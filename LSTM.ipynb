{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca4d724",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "First read the json files containing the news article data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f11de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>source</th>\n",
       "      <th>bias</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "      <th>content_original</th>\n",
       "      <th>source_url</th>\n",
       "      <th>bias_text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>terrorism</td>\n",
       "      <td>New York Times - News</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.nytimes.com/2016/09/20/nyregion/ahm...</td>\n",
       "      <td>Bomb Suspect Changed After Trip Abroad, Friend...</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>N. R. Kleinfield</td>\n",
       "      <td>Besides his most recent trip to Quetta , Mr. R...</td>\n",
       "      <td>Besides his most recent trip to Quetta, Mr. Ra...</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>left</td>\n",
       "      <td>004Gt3gcsotuiYmz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supreme_court</td>\n",
       "      <td>Vox</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.vox.com/policy-and-politics/2018/9...</td>\n",
       "      <td>Why Susan Collins claims she’s being bribed ov...</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>Emily Stewart, Terry Nguyen, Rebecca Jennings,...</td>\n",
       "      <td>Is Maine Republican Sen. Susan Collins being b...</td>\n",
       "      <td>Is Maine Republican Sen. Susan Collins being b...</td>\n",
       "      <td>www.vox.com</td>\n",
       "      <td>left</td>\n",
       "      <td>00eP4XD3VdMmHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>Ezra Klein</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.npr.org/blogs/thetwo-way/2014/05/06...</td>\n",
       "      <td>Poll: Prestigious Colleges Won't Make You Happ...</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>Anya Kamenetz</td>\n",
       "      <td>Poll : Prestigious Colleges Wo n't Make You Ha...</td>\n",
       "      <td>Poll: Prestigious Colleges Won't Make You Happ...</td>\n",
       "      <td>www.npr.org</td>\n",
       "      <td>left</td>\n",
       "      <td>00FTGIZEd6B8zQ4U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us_house</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.breitbart.com/big-government/2017/0...</td>\n",
       "      <td>Paul Ryan Reportedly Says No Chance for Border...</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>Ian Mason</td>\n",
       "      <td>House Speaker Paul Ryan , at a private dinner ...</td>\n",
       "      <td>House Speaker Paul Ryan, at a private dinner e...</td>\n",
       "      <td>www.breitbart.com</td>\n",
       "      <td>right</td>\n",
       "      <td>00HGGqBRf1kzPRlg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white_house</td>\n",
       "      <td>Guest Writer - Left</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.cnn.com/2019/07/11/politics/donald...</td>\n",
       "      <td>OPINION: Trump seeking change of legal fortune...</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>Analysis Stephen Collinson</td>\n",
       "      <td>( CNN ) President Donald Trump has reason to h...</td>\n",
       "      <td>(CNN) President Donald Trump has reason to hop...</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>left</td>\n",
       "      <td>00IzI5ynahBVtC9l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37549</th>\n",
       "      <td>race_and_racism</td>\n",
       "      <td>Yahoo! The 360</td>\n",
       "      <td>1</td>\n",
       "      <td>https://news.yahoo.com/how-do-we-address-racis...</td>\n",
       "      <td>How do we address racism in 'Gone With the Wind'?</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>Julia Munslow</td>\n",
       "      <td>“ The 360 ” shows you diverse perspectives on ...</td>\n",
       "      <td>“The 360” shows you diverse perspectives on th...</td>\n",
       "      <td>www.news.yahoo.com</td>\n",
       "      <td>center</td>\n",
       "      <td>zzwPV6NCYsMiDb0a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>elections</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>1</td>\n",
       "      <td>https://thehill.com/homenews/campaign/445504-t...</td>\n",
       "      <td>The top 10 Democrats in the 2020 race</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td></td>\n",
       "      <td>The race for the Democratic presidential nomin...</td>\n",
       "      <td>The race for the Democratic presidential nomin...</td>\n",
       "      <td>www.thehill.com</td>\n",
       "      <td>center</td>\n",
       "      <td>zZwwVzN0ZltBq302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37551</th>\n",
       "      <td>violence_in_america</td>\n",
       "      <td>Townhall</td>\n",
       "      <td>2</td>\n",
       "      <td>https://townhall.com/tipsheet/leahbarkoukis/20...</td>\n",
       "      <td>Report: Police Questioned YouTube Shooter Morn...</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>Leah Barkoukis, Matt Vespa, Timothy Meads, Kat...</td>\n",
       "      <td>Police confirmed they found and questioned Nas...</td>\n",
       "      <td>Police confirmed they found and questioned Nas...</td>\n",
       "      <td>www.townhall.com</td>\n",
       "      <td>right</td>\n",
       "      <td>ZzXppS8L4v4WsVWq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>free_speech</td>\n",
       "      <td>NPR Online News</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.npr.org/blogs/parallels/2015/02/10/...</td>\n",
       "      <td>The French Debate: Free Speech Versus Hate Speech</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>Eleanor Beardsley</td>\n",
       "      <td>When terrorists attacked a satirical magazine ...</td>\n",
       "      <td>The French Debate: Free Speech Versus Hate Spe...</td>\n",
       "      <td>www.npr.org</td>\n",
       "      <td>center</td>\n",
       "      <td>zzZMTdCEiAiVRRO3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37553</th>\n",
       "      <td>us_military</td>\n",
       "      <td>The Intercept</td>\n",
       "      <td>0</td>\n",
       "      <td>https://theintercept.com/2020/01/09/donald-tru...</td>\n",
       "      <td>Donald Trump Murdered Qassim Suleimani</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td></td>\n",
       "      <td>Donald Trump has dragged America into a moral ...</td>\n",
       "      <td>Photo: Jabin Botsford/The Washington Post via ...</td>\n",
       "      <td>www.theintercept.com</td>\n",
       "      <td>left</td>\n",
       "      <td>ZzzzVEQgXqh4BzgV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37554 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic                 source bias  \\\n",
       "0                terrorism  New York Times - News    0   \n",
       "1            supreme_court                    Vox    0   \n",
       "2                education             Ezra Klein    0   \n",
       "3                 us_house         Breitbart News    2   \n",
       "4              white_house    Guest Writer - Left    0   \n",
       "...                    ...                    ...  ...   \n",
       "37549      race_and_racism         Yahoo! The 360    1   \n",
       "37550            elections               The Hill    1   \n",
       "37551  violence_in_america               Townhall    2   \n",
       "37552          free_speech        NPR Online News    1   \n",
       "37553          us_military          The Intercept    0   \n",
       "\n",
       "                                                     url  \\\n",
       "0      http://www.nytimes.com/2016/09/20/nyregion/ahm...   \n",
       "1      https://www.vox.com/policy-and-politics/2018/9...   \n",
       "2      http://www.npr.org/blogs/thetwo-way/2014/05/06...   \n",
       "3      http://www.breitbart.com/big-government/2017/0...   \n",
       "4      https://www.cnn.com/2019/07/11/politics/donald...   \n",
       "...                                                  ...   \n",
       "37549  https://news.yahoo.com/how-do-we-address-racis...   \n",
       "37550  https://thehill.com/homenews/campaign/445504-t...   \n",
       "37551  https://townhall.com/tipsheet/leahbarkoukis/20...   \n",
       "37552  http://www.npr.org/blogs/parallels/2015/02/10/...   \n",
       "37553  https://theintercept.com/2020/01/09/donald-tru...   \n",
       "\n",
       "                                                   title        date  \\\n",
       "0      Bomb Suspect Changed After Trip Abroad, Friend...  2016-09-20   \n",
       "1      Why Susan Collins claims she’s being bribed ov...  2018-09-12   \n",
       "2      Poll: Prestigious Colleges Won't Make You Happ...  2014-05-06   \n",
       "3      Paul Ryan Reportedly Says No Chance for Border...  2017-09-12   \n",
       "4      OPINION: Trump seeking change of legal fortune...  2019-07-11   \n",
       "...                                                  ...         ...   \n",
       "37549  How do we address racism in 'Gone With the Wind'?  2020-06-18   \n",
       "37550              The top 10 Democrats in the 2020 race  2019-05-28   \n",
       "37551  Report: Police Questioned YouTube Shooter Morn...  2018-04-04   \n",
       "37552  The French Debate: Free Speech Versus Hate Speech  2015-02-10   \n",
       "37553             Donald Trump Murdered Qassim Suleimani  2020-01-09   \n",
       "\n",
       "                                                 authors  \\\n",
       "0                                       N. R. Kleinfield   \n",
       "1      Emily Stewart, Terry Nguyen, Rebecca Jennings,...   \n",
       "2                                          Anya Kamenetz   \n",
       "3                                              Ian Mason   \n",
       "4                             Analysis Stephen Collinson   \n",
       "...                                                  ...   \n",
       "37549                                      Julia Munslow   \n",
       "37550                                                      \n",
       "37551  Leah Barkoukis, Matt Vespa, Timothy Meads, Kat...   \n",
       "37552                                  Eleanor Beardsley   \n",
       "37553                                                      \n",
       "\n",
       "                                                 content  \\\n",
       "0      Besides his most recent trip to Quetta , Mr. R...   \n",
       "1      Is Maine Republican Sen. Susan Collins being b...   \n",
       "2      Poll : Prestigious Colleges Wo n't Make You Ha...   \n",
       "3      House Speaker Paul Ryan , at a private dinner ...   \n",
       "4      ( CNN ) President Donald Trump has reason to h...   \n",
       "...                                                  ...   \n",
       "37549  “ The 360 ” shows you diverse perspectives on ...   \n",
       "37550  The race for the Democratic presidential nomin...   \n",
       "37551  Police confirmed they found and questioned Nas...   \n",
       "37552  When terrorists attacked a satirical magazine ...   \n",
       "37553  Donald Trump has dragged America into a moral ...   \n",
       "\n",
       "                                        content_original  \\\n",
       "0      Besides his most recent trip to Quetta, Mr. Ra...   \n",
       "1      Is Maine Republican Sen. Susan Collins being b...   \n",
       "2      Poll: Prestigious Colleges Won't Make You Happ...   \n",
       "3      House Speaker Paul Ryan, at a private dinner e...   \n",
       "4      (CNN) President Donald Trump has reason to hop...   \n",
       "...                                                  ...   \n",
       "37549  “The 360” shows you diverse perspectives on th...   \n",
       "37550  The race for the Democratic presidential nomin...   \n",
       "37551  Police confirmed they found and questioned Nas...   \n",
       "37552  The French Debate: Free Speech Versus Hate Spe...   \n",
       "37553  Photo: Jabin Botsford/The Washington Post via ...   \n",
       "\n",
       "                 source_url bias_text                ID  \n",
       "0           www.nytimes.com      left  004Gt3gcsotuiYmz  \n",
       "1               www.vox.com      left  00eP4XD3VdMmHITE  \n",
       "2               www.npr.org      left  00FTGIZEd6B8zQ4U  \n",
       "3         www.breitbart.com     right  00HGGqBRf1kzPRlg  \n",
       "4               www.cnn.com      left  00IzI5ynahBVtC9l  \n",
       "...                     ...       ...               ...  \n",
       "37549    www.news.yahoo.com    center  zzwPV6NCYsMiDb0a  \n",
       "37550       www.thehill.com    center  zZwwVzN0ZltBq302  \n",
       "37551      www.townhall.com     right  ZzXppS8L4v4WsVWq  \n",
       "37552           www.npr.org    center  zzZMTdCEiAiVRRO3  \n",
       "37553  www.theintercept.com      left  ZzzzVEQgXqh4BzgV  \n",
       "\n",
       "[37554 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'data\\jsons'\n",
    "\n",
    "dfs = [] # an empty list to store the data frames\n",
    "for f in os.listdir(directory):\n",
    "    file = os.path.join(directory, f)\n",
    "    data = pd.read_json(file, typ='series').to_frame().T # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e42c2",
   "metadata": {},
   "source": [
    "For this proof of concept we are going to use the preprocessed data provided in the dataset so we can drop the unused columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101e5579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Besides his most recent trip to Quetta , Mr. R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Is Maine Republican Sen. Susan Collins being b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Poll : Prestigious Colleges Wo n't Make You Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>House Speaker Paul Ryan , at a private dinner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>( CNN ) President Donald Trump has reason to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37549</th>\n",
       "      <td>1</td>\n",
       "      <td>“ The 360 ” shows you diverse perspectives on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>1</td>\n",
       "      <td>The race for the Democratic presidential nomin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37551</th>\n",
       "      <td>2</td>\n",
       "      <td>Police confirmed they found and questioned Nas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>1</td>\n",
       "      <td>When terrorists attacked a satirical magazine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37553</th>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump has dragged America into a moral ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37554 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bias                                            content\n",
       "0        0  Besides his most recent trip to Quetta , Mr. R...\n",
       "1        0  Is Maine Republican Sen. Susan Collins being b...\n",
       "2        0  Poll : Prestigious Colleges Wo n't Make You Ha...\n",
       "3        2  House Speaker Paul Ryan , at a private dinner ...\n",
       "4        0  ( CNN ) President Donald Trump has reason to h...\n",
       "...    ...                                                ...\n",
       "37549    1  “ The 360 ” shows you diverse perspectives on ...\n",
       "37550    1  The race for the Democratic presidential nomin...\n",
       "37551    2  Police confirmed they found and questioned Nas...\n",
       "37552    1  When terrorists attacked a satirical magazine ...\n",
       "37553    0  Donald Trump has dragged America into a moral ...\n",
       "\n",
       "[37554 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['topic', 'source', 'url', 'title', 'date', 'authors', 'content_original', 'source_url', 'bias_text', 'ID'],\n",
    "        axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d300c96",
   "metadata": {},
   "source": [
    "Next, remove all punctuation from the text, make all the words lowercase, remove stop words, tokenize and one-hot-encode the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a7e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_29164\\1819813345.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>besides his most recent trip to quetta  mr rah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is maine republican sen susan collins being br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>poll  prestigious colleges wo nt make you happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>house speaker paul ryan  at a private dinner e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cnn  president donald trump has reason to hop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bias                                            content\n",
       "0    0  besides his most recent trip to quetta  mr rah...\n",
       "1    0  is maine republican sen susan collins being br...\n",
       "2    0  poll  prestigious colleges wo nt make you happ...\n",
       "3    2  house speaker paul ryan  at a private dinner e...\n",
       "4    0   cnn  president donald trump has reason to hop..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].str.replace('[^\\w\\s]','')\n",
    "df['content'] = df['content'].str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf039a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65f274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "get average article word length to use as word count limit for LSTM, \n",
    "articles that are shorter than this will be zero-padded\n",
    "'''\n",
    "max_length = int(np.round(df['content'].apply(len).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a29d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203115 unique tokens. Distilled to 203115 top words.\n",
      "Shape of data tensor: (37554, 3970)\n",
      "3969\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "X = df['content'].to_numpy()\n",
    "\n",
    "NUM_TOP_WORDS = None\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_length)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "X = sequence.pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print(np.max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ee2fd",
   "metadata": {},
   "source": [
    "Let's check the class distribution for our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346ffa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=object), array([13005, 10815, 13734], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['bias'].to_numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1581d",
   "metadata": {},
   "source": [
    "As we can see they are relatively balanced so we can go ahead and split this into our train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533b5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30042 3756 3756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import backend\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['bias'].to_numpy(), test_size=0.1, stratify=df['bias'].to_numpy())\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1.0/9.0, stratify=y_train)\n",
    "\n",
    "NUM_CLASSES = len(np.unique(df['bias']))\n",
    "y_train_ohe = keras.utils.np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.np_utils.to_categorical(y_test, NUM_CLASSES)\n",
    "y_val_ohe = keras.utils.np_utils.to_categorical(y_val, NUM_CLASSES)\n",
    "\n",
    "print(len(X_train), len(X_test), len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80eb22",
   "metadata": {},
   "source": [
    "With our dataset split we will now create a pre-trained embedding matrix using GloVe to be used with the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9041b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Embedding Shape: (203116, 300) \n",
      " Total words found: 94645 \n",
      " Percentage: 46.596526123003606\n",
      "CPU times: total: 20.1 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 300\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "      \"Total words found:\",found_words, \"\\n\",\n",
    "      \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b716d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# create pre-trained embedding layer\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a814d7e",
   "metadata": {},
   "source": [
    "Now let's build and train the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7adfe1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3970, 300)         60934800  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 61,656,903\n",
      "Trainable params: 722,103\n",
      "Non-trainable params: 60,934,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(embedding_layer)\n",
    "lstm.add(LSTM(300,dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "lstm.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99ba804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/lstm/while/body/_1/sequential/lstm/while/lstm_cell/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3921]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_ohe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_ohe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/lstm/while/body/_1/sequential/lstm/while/lstm_cell/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3921]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = lstm.fit(X_train, y_train_ohe, validation_data=(X_val, y_val_ohe), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37c219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
